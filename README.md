# ğŸ¤– Townbase Chatbot Demo

## 1ï¸âƒ£ Summary

This project is a **full-stack chatbot** prototype built for the **Townbase assignment**.
It connects users with **local event data** from the Townbase API and enhances the experience with **LLM models (OpenAI)** for query interpretation, spelling correction, and natural conversational responses.

### ğŸ”¹ Backend (Node.js + Express)

* ğŸš€ REST API (`/api/chat`) that:

  * ğŸ“ Accepts free-form user queries.
  * ğŸ§  Uses **LLM (OpenAI)** to interpret intent (fix spelling, extract keywords, infer date/city).
  * ğŸŸ Fetches events from **Townbase Public API**.
  * ğŸ’¬ Uses **LLM summarization** to return natural, chat-like answers.
* ğŸ”‘ Configurable with `.env`.

### ğŸ”¹ Frontend (Angular + SCSS)

* ğŸ’» Simple **chat interface** styled with SCSS.
* ğŸ‘¤ User types queries â†’ calls backend `/api/chat`.
* ğŸ’¬ Displays **chat bubbles** for user + bot.
* ğŸŸ Shows event name, time, location, and links.

### âš¡ Performance note

Right now the chatbot may feel **a bit slow** due to:

* â³ LLM latency (2 calls per query).
* ğŸ¢ Townbase API response time.

**How to improve**:

* ğŸ”„ Add **Redis caching** for repeated queries.
* âš¡ Use **streaming responses** from OpenAI.
* ğŸ§© Merge interpretation + summarization in a single LLM call.
* ğŸ¤– Try smaller/faster models (`gpt-4o-mini`, local LLM).

---

## 2ï¸âƒ£ How to Start

### ğŸ”¹ Backend (Node.js + Express)

```bash
cd backend
npm install
cp .env.example .env   # add your API keys
npm run dev
```

ğŸ‘‰ Runs at: **[http://localhost:8000](http://localhost:8000)**

### ğŸ”¹ Frontend (Angular + SCSS)

```bash
cd frontend
npm install
ng serve --open
```

ğŸ‘‰ Runs at: **[http://localhost:4200](http://localhost:4200)**

---

## 3ï¸âƒ£ Test ğŸ§ª

Manual test:

1. Run **backend** + **frontend**.
2. Open browser â†’ [http://localhost:4200](http://localhost:4200).
3. Ask queries like:

   * ğŸ¶ â€œsho me concarts in helsinki tommorowâ€ â†’ spelling fixed âœ…
   * ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ â€œevents for kids next weekendâ€ â†’ filtered âœ…
   * ğŸ˜‚ â€œany comedy shows tonight?â€ â†’ fallback suggestions âœ…

Bot should reply with a **friendly summary + structured event list**.

---

## 4ï¸âƒ£ How to Scale It ğŸ“ˆ

### Backend

* ğŸ—„ Cache with **Redis**.
* ğŸ“© Queue with **RabbitMQ/Kafka** for heavy traffic.
* ğŸ”¥ Split into microservices (LLM service, API proxy, frontend).
* â˜ï¸ Deploy on **Kubernetes (HPA autoscaling)**.

### Frontend

* ğŸ“¦ Build: `ng build --configuration production`
* ğŸŒ Serve via **Nginx/CDN**.
* ğŸ” Add **Angular Universal** (SSR) for SEO.

### LLM

* âš¡ Use smaller models for query parsing.
* ğŸ¯ Run summarization only for premium users.
* ğŸ“š Add **RAG pipelines** for historical events.

---

## ğŸ— Architecture

Hereâ€™s how the system works:

```mermaid
flowchart LR
    User[ğŸ‘¤ User] --> |Query| Frontend[ğŸ’» Angular Chat UI]
    Frontend --> |/api/chat| Backend[âš™ï¸ Node.js + Express]

    Backend --> |1. Interpret Query| LLM[ğŸ§  OpenAI LLM]
    Backend --> |2. Fetch Events| TownbaseAPI[ğŸŸ Townbase Public API]
    Backend --> |3. Summarize Results| LLM

    Backend --> |Reply JSON + Summary| Frontend
    Frontend --> |Chat Bubble UI| User
```

---

âœ… With this setup you delivered:

* ğŸ¯ **Full-stack chatbot** (Angular frontend + Node backend).
* ğŸ”— **Townbase API integration**.
* ğŸ§  **LLM-powered natural UX**.
* ğŸš€ Future-ready with scaling plan + AI extensions.

---
